{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio práctico: Limpieza y transformación de un dataset biosanitario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tema 3: Aplicación de aspectos avanzados de procesamiento de datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objetivo práctico: Aplicar técnicas de limpieza y preprocesamiento de datos para preparar un conjunto de datos para su análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En este ejercicio, vais a trabajar con un conjunto de datos sintéticos\n",
    "biosanitarios contenido en un único archivo CSV titulado\n",
    "pacientes_sintetico.csv. Este dataset simula registros de pacientes con\n",
    "columnas como edad, presión arterial, niveles de colesterol y frecuencia\n",
    "cardíaca máxima. El archivo ha sido diseñado para incluir imperfecciones\n",
    "comunes: valores nulos, duplicados y columnas numéricas que necesitan\n",
    "normalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vuestra tarea consiste en usar este archivo CSV y realizar las siguientes actividades utilizando Python y bibliotecas como pandas, numpy y sklearn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas, numoy, sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'pacientes_sintetico.csv'\n",
    "data = pd.read_csv(ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imputar valores nulos:\n",
    "Identificad las columnas con valores faltantes (por ejemplo,\n",
    "\"colesterol\" o \"presión arterial\") y rellenadlos utilizando el promedio\n",
    "(para datos continuos) o la mediana (para datos con distribuciones no\n",
    "uniformes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estas son las columnas nulas: Index(['presion_arterial', 'colesterol'], dtype='object')\n",
      "Valores nulos después de la imputación:\n",
      "id_paciente          0\n",
      "edad                 0\n",
      "presion_arterial     0\n",
      "colesterol           0\n",
      "frec_cardiaca_max    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificar columnas con valores nulos\n",
    "columnas_nulas = data.columns[data.isnull().any()]\n",
    "print(f'\\nEstas son las columnas nulas: {columnas_nulas}')\n",
    "\n",
    "# Función para imputar valores nulos\n",
    "def imputar_valores_nulos(data):\n",
    "    for columna in columnas_nulas:\n",
    "        if data[columna].dtype in ['float64', 'int64']:\n",
    "            media = data[columna].mean()\n",
    "            data[columna] = data[columna].fillna(media)\n",
    "        else:  # Para datos categóricos\n",
    "            moda = data[columna].mode()[0]\n",
    "            data[columna] = data[columna].fillna(moda)\n",
    "    return data\n",
    "\n",
    "# Imputar valores nulos\n",
    "data = imputar_valores_nulos(data)\n",
    "\n",
    "print(\"Valores nulos después de la imputación:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Eliminar duplicados:\n",
    "Buscad y eliminad cualquier fila duplicada en el dataset para asegurar\n",
    "que cada paciente esté representado una sola vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sin_duplicados = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normalizar una columna numérica:\n",
    "Elegid una columna numérica del CSV (como \"edad\" o \"colesterol\") y\n",
    "aplicad la técnica de min-max scaling para escalar sus valores al rango\n",
    "[0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_paciente      edad  presion_arterial  colesterol  frec_cardiaca_max\n",
      "0            1  0.622951         74.700000       245.5                106\n",
      "1            2  0.836066        122.800000       216.0                 64\n",
      "2            3  0.459016        147.000000       212.4                121\n",
      "3            4  0.229508        119.533443       154.9                143\n",
      "4            5  0.688525        123.100000       153.7                192\n"
     ]
    }
   ],
   "source": [
    "columna_a_normalizar = 'edad'  # Cambia esto por la columna que desees\n",
    "# Aplicar min-max scaling\n",
    "min_val = data[columna_a_normalizar].min()\n",
    "max_val = data[columna_a_normalizar].max()\n",
    "# Normalizar los valores\n",
    "data[columna_a_normalizar] = (data[columna_a_normalizar] - min_val) / (max_val - min_val)\n",
    "# Mostrar el DataFrame con la columna normalizada\n",
    "print(data.head())\n",
    "\n",
    "# Guardar el DataFrame con la columna normalizada\n",
    "ruta_normalizado = 'pacientes_normalizado.csv'\n",
    "data.to_csv(ruta_normalizado, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usad el archivo pacientes_sintetico.csv que se os proporcionará (o\n",
    "generadlo con el código de ejemplo que se incluye más abajo).\n",
    "- Cargad el archivo en Python, limpiadlo y transformadlo.\n",
    "- Documentad vuestros pasos en el código con comentarios que expliquen qué\n",
    "hacéis y por qué."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un script de Python con el código completo que realice las tres tareas a\n",
    "partir del archivo CSV.\n",
    "- Un resumen breve (puede ser en comentarios en el código) donde\n",
    "indiquéis:\n",
    "    - Qué columnas tenían valores nulos y cómo las tratasteis.\n",
    "    - Cuántos duplicados eliminasteis.\n",
    "    - Qué significa un valor normalizado (por ejemplo, 0 o 1) en la columna que elegisteis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginad que sois analistas de datos en un hospital preparando un archivo CSV\n",
    "con información clínica simulada para un estudio piloto sobre factores de\n",
    "riesgo cardiovascular. La calidad de los datos es clave para obtener\n",
    "resultados fiables, ¡así que aseguraos de que el dataset esté bien limpio y\n",
    "listo para el análisis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
