{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TUTORIAL: ¡SCIKIT-LEARN DESDE CERO!\n",
        "\n",
        "En este tutorial veremos paso a paso todos los elementos básicos que usualmente hay que tener en cuenta para crear, entrenar, validar y poner a prueba prácticamente cualquier modelo de Machine Learning clásico usando esta librería.\n",
        "\n",
        "Contenido:\n",
        "\n",
        "1. [¿Qué es Scikit-Learn?](#scrollTo=Mwb3z4nhqir3&line=1&uniqifier=1)\n",
        "2. [El flujo de trabajo convencional en Scikit-Learn](#scrollTo=l7BA3TMarh4z&line=1&uniqifier=1)\n",
        "3. [Pre-procesamiento: generar particiones](#scrollTo=Eqs5h_Ijv6Mc&line=1&uniqifier=1)\n",
        "4. [Pre-procesamiento: transformadores](#scrollTo=Xn2shF8Vz-UQ&line=1&uniqifier=1)\n",
        "5. [Crear, entrenar y validar el modelo: estimadores](#scrollTo=BtFsAQYJg-JL&line=1&uniqifier=1)\n",
        "6. [*Pipelines*](#scrollTo=Zy6KK9A7jtdr&line=1&uniqifier=1)\n"
      ],
      "metadata": {
        "id": "fhYpws-kWuj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. ¿Qué es Scikit-Learn?\n",
        "\n",
        "> Scikit-learn es una librería de Machine Learning de código abierto que contiene herramientas para **pre-procesamiento** de datos, **entrenamiento** y generación de **predicciones** con diferentes modelos **clásicos** y **selección y validación** de modelos, entre otras.\n",
        "\n",
        "Este es el panorama general de los diferentes algoritmos de Machine Learning implementados en Scikit-Learn:\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://scikit-learn.org/1.4/_static/ml_map.png\" style=\"width:100%\">\n",
        "<figcaption align = \"center\"> Los diferentes algoritmos de Scikit-Learn (tomada del sitio web oficial de la librería) </figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "Mwb3z4nhqir3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. El flujo de trabajo convencional en Scikit-Learn\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1uyNbPoI1zX8BG4ISyD9Kud54ydI67mqu)\n",
        "\n",
        "En esencia:\n",
        "\n",
        "- Podemos implementar modelos para tareas de aprendizaje supervisado (como clasificación o regresión) o para aprendizaje NO supervisado (como *clustering*)\n",
        "- En el **pre-procesamiento** generalmente debemos **generar particiones** de los sets de datos (en entrenamiento, validación y prueba) o realizar **transformaciones** de los datos (como el escalamiento)\n",
        "- Luego **creamos una instancia del algoritmo**, **entrenamos** el modelo y lo **validamos** con los sets de entrenamiento, validación y/o prueba\n",
        "- Finalmente, el modelo está listo para **generar predicciones**\n",
        "\n",
        "Veamos de forma práctica los elementos básicos de cada una de estas etapas."
      ],
      "metadata": {
        "id": "l7BA3TMarh4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Pre-procesamiento: generar particiones\n",
        "\n",
        "Una tarea común consiste en dividir el set de datos en los sets de entrenamiento, validación y prueba.\n",
        "\n",
        "Esto lo podemos hacer con la función `train_test_split`.\n",
        "\n",
        "Para entender cómo usarla comencemos leyendo el set de datos `particiones_datos_balanceados.npz` (arreglo de NumPy):\n",
        "\n"
      ],
      "metadata": {
        "id": "Eqs5h_Ijv6Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.load('/content/particiones-datos-balanceados.npz')['X']\n",
        "Y = np.load('/content/particiones-datos-balanceados.npz')['Y']\n",
        "\n",
        "'''print(X.shape)\n",
        "print(Y.shape)'''\n",
        "Y"
      ],
      "metadata": {
        "id": "4V1kfGbYXyF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bca650f-260d-4313-ccd9-34e50fbe6275"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso tenemos un set de datos supervisado, con:\n",
        "\n",
        "- `X`: el arreglo de entrada al modelo (20 datos x 3 características)\n",
        "- `Y`: la variable que deberá aprender a predecir el modelo (20 datos)\n",
        "\n",
        "> **Nota importante:** los arreglos siempre deben estar dimensionados como *n_datos x n_características* (X) y *n_datos* (Y)\n",
        "\n",
        "Supongamos que queremos realizar la partición con estas proporciones:\n",
        "\n",
        "- Entrenamiento: 60%\n",
        "- Validación: 20%\n",
        "- Prueba: 20%\n",
        "\n",
        "En este caso debemos usar `train_test_split` dos veces:\n",
        "\n",
        "- En el primer paso partimos el set de datos en 2: 60% (entrenamiento) y 40% (resto)\n",
        "- En el segundo paso partimos el set de datos restante en 2 mitades: 50% (20% del dataset original, validación) y 50% (20% del dataset original, prueba)\n",
        "\n",
        "Veamos cómo implementar esta partición:"
      ],
      "metadata": {
        "id": "LfHm72h6wieb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Partición 60% (train) y resto (40%)\n",
        "x_train, x_resto, y_train, y_resto = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "#Partición 'resto' en 2 mitades\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_resto, y_resto, test_size=0.5, random_state=321)\n",
        "\n",
        "#verificación\n",
        "print('Tamaños: ')\n",
        "print('\\tDataset original: ', X.shape, Y.shape)\n",
        "print('\\tEntrenamiento: ', x_train.shape, y_train.shape)\n",
        "print('\\tValidación: ', x_val.shape, y_val.shape)\n",
        "print('\\tPrueba: ', x_test.shape, y_test.shape)\n",
        "\n",
        "print('Proporciones categorías (0s/1s): ')\n",
        "print(f'\\tDataset original: {np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')\n",
        "print(f'\\tEntrenamiento: {np.sum(y_train==0)/len(y_train)}/{np.sum(y_train==1)/len(y_train)}')\n",
        "print(f'\\tValidación: {np.sum(y_val==0)/len(y_val)}/{np.sum(y_val==1)/len(y_val)}')\n",
        "print(f'\\tPrueba: {np.sum(y_test==0)/len(y_test)}/{np.sum(y_test==1)/len(y_test)}')"
      ],
      "metadata": {
        "id": "peadkCmkX1_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda2510f-8cef-481e-da98-c756b245c06a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaños: \n",
            "\tDataset original:  (20, 3) (20,)\n",
            "\tEntrenamiento:  (12, 3) (12,)\n",
            "\tValidación:  (4, 3) (4,)\n",
            "\tPrueba:  (4, 3) (4,)\n",
            "Proporciones categorías (0s/1s): \n",
            "\tDataset original: 0.55/0.45\n",
            "\tEntrenamiento: 0.5833333333333334/0.4166666666666667\n",
            "\tValidación: 0.5/0.5\n",
            "\tPrueba: 0.5/0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso anterior lo que hace `train_test_split` es:\n",
        "\n",
        "1. Mezclar aleatoriamente el set de datos\n",
        "2. Generar las particiones con las proporciones correspondientes\n",
        "\n",
        "Es decir, en últimas crea cada subset usando **muestreo aleatorio**.\n",
        "\n",
        "Este muestreo aleatorio es adecuado si por ejemplo estamos implementando un clasificador y las categorías están balanceadas, es decir, tienen más o menos la misma proporción de una categoría o de otra (como es el caso del ejemplo anterior).\n",
        "\n",
        "Sin embargo, este muestreo aleatorio no es adecuado si tenemos datos desbalanceados, es decir con una proporción mayor de una categoría que de otra.\n",
        "\n",
        "Por ejemplo, leamos el dataset `particiones-datos-desbalanceados.npz` y veamos la proporción de los datos:"
      ],
      "metadata": {
        "id": "OT5__Hatx11i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('/content/particiones-datos-desbalanceados.npz')['X']\n",
        "Y = np.load('/content/particiones-datos-desbalanceados.npz')['Y']\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "49CDb6cdX4eW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092508e7-8d84-431c-e1eb-718b66c3bb75"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.75275929  1.11852895 -7.5592353 ]\n",
            " [ 2.70428584 -3.60506139 -0.0964618 ]\n",
            " [ 1.39196365 -2.07855351 -9.31222958]\n",
            " [ 0.59195091 -1.33638157  8.18640804]\n",
            " [-2.06388816 -0.43930016 -4.82440037]\n",
            " [-2.06403288  2.85175961  3.25044569]\n",
            " [-2.65149833 -3.00326218 -3.76577848]\n",
            " [ 2.19705687  0.14234438  0.40136042]\n",
            " [ 0.60669007  0.92414569  0.93420559]\n",
            " [ 1.24843547 -4.53549587 -6.30291089]\n",
            " [-2.87649303  1.07544852  9.39169256]\n",
            " [ 2.81945911 -3.29475876  5.50265647]\n",
            " [ 1.99465584 -4.34948407  8.78997883]\n",
            " [-1.72596534  4.48885537  7.89654701]\n",
            " [-1.9090502   4.65632033  1.95799958]\n",
            " [-1.89957294  3.08397348  8.4374847 ]\n",
            " [-1.17454654 -1.95386231 -8.23014996]\n",
            " [ 0.14853859 -4.02327886 -6.08034275]\n",
            " [-0.40832989  1.84233027 -9.09545422]\n",
            " [-1.25262516 -0.59847506 -3.49339338]]\n",
            "[1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proporción categorías 1 y 0\n",
        "print('Proporciones categorías (0s/1s) set desbalanceado: ')\n",
        "print(f'\\t{np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')"
      ],
      "metadata": {
        "id": "cclUDuoZX6k4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af16c434-f087-4697-fca3-da839fb11207"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proporciones categorías (0s/1s) set desbalanceado: \n",
            "\t0.8/0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Claramente es un set desbalanceado: 85% categoría \"0\" y 15% categoría \"1\".\n",
        "\n",
        "Así que si hacemos la partición y queremos por ejemplo implementar un modelo de detección de anomalías **debemos preservar estas proporciones**.\n",
        "\n",
        "Esto se logra usando `train_test_split` pero usando un **muestreo estratificado**. En este caso simplemente usamos el argumento `stratify = Y` para que al hacer el muestreo la función tenga en cuenta las proporciones presentes en el arreglo `Y`:"
      ],
      "metadata": {
        "id": "Oe1BDv34ygtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partición con muestreo estratificado\n",
        "\n",
        "# Partición 60% (train) y resto (40%)\n",
        "x_train, x_resto, y_train, y_resto = train_test_split(\n",
        "    X, Y, test_size=0.4, random_state=20,\n",
        "    stratify=Y, #*** MUESTREO ESTRATIFICADO ***\n",
        ")\n",
        "\n",
        "# Partición \"resto\" en 2 mitades (también estratificado)\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_resto, y_resto, test_size=0.5, random_state=321,\n",
        "    stratify = y_resto, #*** MUESTREO ESTRATIFICADO ***\n",
        ")\n",
        "\n",
        "# Verificación\n",
        "print('Tamaños: ')\n",
        "print('\\tDataset original: ', X.shape, Y.shape)\n",
        "print('\\tEntrenamiento: ', x_train.shape, y_train.shape)\n",
        "print('\\tValidación: ', x_val.shape, y_val.shape)\n",
        "print('\\tPrueba: ', x_test.shape, y_test.shape)\n",
        "\n",
        "print('Proporciones categorías (0s/1s): ')\n",
        "print(f'\\tDataset original: {np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')\n",
        "print(f'\\tEntrenamiento: {np.sum(y_train==0)/len(y_train)}/{np.sum(y_train==1)/len(y_train)}')\n",
        "print(f'\\tValidación: {np.sum(y_val==0)/len(y_val)}/{np.sum(y_val==1)/len(y_val)}')\n",
        "print(f'\\tPrueba: {np.sum(y_test==0)/len(y_test)}/{np.sum(y_test==1)/len(y_test)}')"
      ],
      "metadata": {
        "id": "NFk3DM9pX9op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698c0ddd-8f1c-436b-e9dd-28068e41a4dd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaños: \n",
            "\tDataset original:  (20, 3) (20,)\n",
            "\tEntrenamiento:  (12, 3) (12,)\n",
            "\tValidación:  (4, 3) (4,)\n",
            "\tPrueba:  (4, 3) (4,)\n",
            "Proporciones categorías (0s/1s): \n",
            "\tDataset original: 0.8/0.2\n",
            "\tEntrenamiento: 0.8333333333333334/0.16666666666666666\n",
            "\tValidación: 0.75/0.25\n",
            "\tPrueba: 0.75/0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el muestreo estratificado intenta mantener las proporciones de cada categoría al generar cada uno de los subsets.\n",
        "\n",
        "Y con esto ya hemos visto cómo implementar una primera fase de pre-procesamiento.\n",
        "\n",
        "Veamos una segunda fase que es el uso de **transformadores**."
      ],
      "metadata": {
        "id": "BHoRCjYOzpMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pre-procesamiento: transformadores\n",
        "\n",
        "> Permiten transformar los datos: escalar (`RobustScaler`, `MinMaxScaler`, `StandardScaler`), codificar (`LabelEncoder`, `OneHotEncoder`) o reducir (`PCA`), entre otras\n",
        "\n",
        "Los pasos para usar un transformador son:\n",
        "\n",
        "1. Crear una instancia del transformador\n",
        "2. Usar el método `fit_transform()` para transformar el set de entrenamiento\n",
        "3. Usar el método `transform()` para transformar los sets de validación y prueba\n",
        "\n",
        "\n",
        "Por ejemplo, veamos los rangos de valores de cada columna en los sets de entrenamiento, validación y prueba (`x_train`, `x_val` y `x_test`):"
      ],
      "metadata": {
        "id": "Xn2shF8Vz-UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x_train: {x_train.min(axis=0)}/{x_train.max(axis=0)}')\n",
        "print(f'x_val: {x_val.min(axis=0)}/{x_val.max(axis=0)}')\n",
        "print(f'x_test: {x_test.min(axis=0)}/{x_test.max(axis=0)}')"
      ],
      "metadata": {
        "id": "PzwNfyp7YAXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253b4ce9-54d7-46a4-a1fb-68010ee76b8d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: [-2.87649303 -4.34948407 -9.31222958]/[2.81945911 3.08397348 9.39169256]\n",
            "x_val: [-2.65149833 -3.00326218 -9.09545422]/[2.19705687 1.84233027 0.40136042]\n",
            "x_test: [-1.9090502  -4.53549587 -8.23014996]/[1.24843547 4.65632033 7.89654701]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que las variables (columnas) tienen diferentes rangos: -3 a 3, -4 a 5 y -9 a 9 aproximadamente.\n",
        "\n",
        "Así que un tipo de pre-procesamiento sería, por ejemplo, escalar cada columna al mismo rango de valores antes de llevar los datos al modelo.\n",
        "\n",
        "Por ejemplo, supongamos que haremos el escalamiento en el rango de -1 a 1 para lo cual podemos usar el transformador `MinMaxScaler`.\n",
        "\n",
        "Veamos cada uno de los pasos a llevar a cabo. En primer lugar creamos una instancia del transformador:"
      ],
      "metadata": {
        "id": "jv3WkwkW3EXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1,1))"
      ],
      "metadata": {
        "id": "q5Wx1HX2YCYw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El segundo paso es usar el método `fit_transform()` aplicado sobre el set de entrenamiento (`x_train`). Este método:\n",
        "\n",
        "- Calculará y almacenará en la instancia los mínimos y máximos de cada columna de `x_train`\n",
        "- Y luego escalará `x_train` al rango de -1 a 1 usando los máximos y mínimos recién calculados\n",
        "\n",
        "Veamos este segundo paso:"
      ],
      "metadata": {
        "id": "_2mHRmhq3uHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit_transform() sobre el set de entrenamiento\n",
        "x_train_s = scaler.fit_transform(x_train)"
      ],
      "metadata": {
        "id": "M01xzCCqYEl7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mínimos de \"x_train\": {x_train.min(axis=0)}')\n",
        "print(f'Mínimos calculados por el escalador: {scaler.data_min_}')\n",
        "print('-'*50)\n",
        "print(f'Máximos de \"x_train\": {x_train.max(axis=0)}')\n",
        "print(f'Máximos calculados por el escalador: {scaler.data_max_}')"
      ],
      "metadata": {
        "id": "GGTiuAy7YGJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd8d4b2-098a-4006-bec3-c8beded775a0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mínimos de \"x_train\": [-2.87649303 -4.34948407 -9.31222958]\n",
            "Mínimos calculados por el escalador: [-2.87649303 -4.34948407 -9.31222958]\n",
            "--------------------------------------------------\n",
            "Máximos de \"x_train\": [2.81945911 3.08397348 9.39169256]\n",
            "Máximos calculados por el escalador: [2.81945911 3.08397348 9.39169256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y verifiquemos que `x_train_s` contiene ahora los datos escalados al rango de -1 a 1:"
      ],
      "metadata": {
        "id": "vfaYCBV64mA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x_train_s: {x_train_s.min(axis=0)}/{x_train_s.max(axis=0)}')"
      ],
      "metadata": {
        "id": "u52OCPfrYHyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5753536b-dbcf-4a63-f47c-6bb8bdfbe07b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_s: [-1. -1. -1.]/[1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tercer paso es tomar el escalador (`scaler`) y usar el método `transform()` para transformar (escalar) los sets de validación (`x_val`) y prueba (`x_test`):"
      ],
      "metadata": {
        "id": "DibC4xix4-nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_s = scaler.transform(x_val)\n",
        "x_test_s = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "LUyuiP-JYJxr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifiquemos que ahora el rango de valores en estos dos sets está entre -1 y 1:"
      ],
      "metadata": {
        "id": "K7O3XXSb5OSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x_val_s: {x_val_s.min(axis=0)}/{x_val_s.max(axis=0)}')\n",
        "print(f'x_test_: {x_test_s.min(axis=0)}/{x_test_s.max(axis=0)}')"
      ],
      "metadata": {
        "id": "9wCJ2pEiYLww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c689db0d-cd0a-4c93-f951-9245eef7a3da"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_val_s: [-0.92099839 -0.63779388 -0.97682033]/[0.78145805 0.66593117 0.03866878]\n",
            "x_test_: [-0.66030514 -1.05004718 -0.88429383]/[0.44837189 1.42304589 0.84012492]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que se realiza el escalamiento pero los valores mínimos y máximos no son exactamente -1 y 1. Esto debido a que el escalamiento se realiza **con base en los valores máximos y mínimos del set de entrenamiento** que no necesariamente son iguales a los de los sets de validación y prueba."
      ],
      "metadata": {
        "id": "dIDQyu9r5bek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Crear, entrenar y validar el modelo: estimadores\n",
        "\n",
        "En Scikit-Learn los modelos se denominan estimadores.\n",
        "\n",
        "La secuencia de uso es la siguiente:\n",
        "\n",
        "1. Crear una instancia del estimador\n",
        "2. Entrenar el modelo con el set de entrenamiento y el método `fit()`\n",
        "3. Validar el modelo con los sets de entrenamiento y validación usando el método `score()`\n",
        "4. Poner a prueba el modelo con el set de prueba y usando los métodos `predict()` y `score()`\n",
        "\n",
        "Veamos en detalle cada uno de estos pasos. Supongamos que tomaremos el set de datos que hemos venido usando para crear, entrenar, validar y poner a prueba un Bosque Aleatorio.\n",
        "\n",
        "El primer paso es crear una instancia de este estimador (`RandomForestClassifier`):"
      ],
      "metadata": {
        "id": "BtFsAQYJg-JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el módulo\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Y crear la instancia\n",
        "bosque = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "8xtyW-n5YN0R"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El segundo paso es entrenarlo. Para ello usamos el método `fit()` y le presentamos como argumentos el set de entrenamiento (`x_train`, `y_train`):"
      ],
      "metadata": {
        "id": "O3M0E1oF8Hxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Entrenamiento\n",
        "bosque.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "LtMyOcsjYQjz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "223d54f8-6bb5-4b22-f03f-f68c81f06970"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tercer paso es validar el modelo. Esto quiere decir que la idea es comparar el desempeño con los sets de entrenamiento y validación, para determinar si hay o no *overfitting* u *underfitting*.\n",
        "\n",
        "El desempeño es simplemente una métrica que cuantifica qué tan bien lo esta haciendo el modelo.\n",
        "\n",
        "Verifiquemos en este caso cuál es el desempeño usado por defecto por el bosque aleatorio:"
      ],
      "metadata": {
        "id": "So00zT_C8jMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bosque.score"
      ],
      "metadata": {
        "id": "cHfaMmR1YTG6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "c755c507-7977-4a31-d60c-811a8aec3bbd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ClassifierMixin.score of RandomForestClassifier()>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.base.ClassifierMixin.score</b><br/>def score(X, y, sample_weight=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/sklearn/base.py</a>Return the mean accuracy on the given test data and labels.\n",
              "\n",
              "In multi-label classification, this is the subset accuracy\n",
              "which is a harsh metric since you require for each sample that\n",
              "each label set be correctly predicted.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "X : array-like of shape (n_samples, n_features)\n",
              "    Test samples.\n",
              "\n",
              "y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
              "    True labels for `X`.\n",
              "\n",
              "sample_weight : array-like of shape (n_samples,), default=None\n",
              "    Sample weights.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "score : float\n",
              "    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 546);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el desempeño se está midiendo con la exactitud promedio (*mean accuracy*).\n",
        "\n",
        "Así que calculemos el desempeño con los sets de entrenamiento y validación:"
      ],
      "metadata": {
        "id": "KwJW49O98ZGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Exactitud promedio entrenamiento: {bosque.score(x_train,y_train)}')\n",
        "print(f'Exactitud promedio validación: {bosque.score(x_val, y_val)}')"
      ],
      "metadata": {
        "id": "-hJbvG9jYW1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a11ea80-1725-47e8-9e34-f4f02849c639"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud promedio entrenamiento: 1.0\n",
            "Exactitud promedio validación: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso vemos que el modelo tiene *overfitting*, pues alcanza un 100% de exactitud con el set de entrenamiento y tan sólo un 50% con el set de prueba.\n",
        "\n",
        "En realidad es de esperar pues tenemos poquísimos datos y no hemos modificado ningún parámetro por defecto del modelo.\n",
        "\n",
        "En una situación real deberíamos recolectar más datos y re-entrenar el modelo, posiblemente afinando sus hiperparámetros (pero esto será tema de un tutorial más avanzado).\n",
        "\n",
        "El cuarto y último paso es poner a prueba el modelo. Para ello podemos primero ver el *score* con el set de prueba:"
      ],
      "metadata": {
        "id": "KbrhJUeW9JYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bosque.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "Y0IP6dk0YYdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00a5992-609e-4355-b79a-03a0c8602aec"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que sigue siendo del 50% por los mismos motivos mencionados anteriormente.\n",
        "\n",
        "Y, suponiendo que estamos conformes con estos resultados, lo que faltaría sería generar predicciones usando el método `predict()`.\n",
        "\n",
        "Tomemos nuevamente el set de prueba y generemos predicciones con el modelo entrenado:"
      ],
      "metadata": {
        "id": "Yjik1h-89rY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = bosque.predict(x_test)"
      ],
      "metadata": {
        "id": "tixQ3UpVYZ-K"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y como tenemos tan pocos datos podemos imprimir el comparativo entre las categorías reales (almacenadas en `y_test`) y las categorías predichas (almacenadas en `y_pred`):"
      ],
      "metadata": {
        "id": "rFwbN8kU982L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Categorías reales:   ', y_test)\n",
        "print('Categorías predichas:', y_pred)"
      ],
      "metadata": {
        "id": "QTGEF2A5YcpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7671e976-9826-4790-aee4-65b4866d6148"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorías reales:    [0 1 0 0]\n",
            "Categorías predichas: [1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y vemos que en efecto de los 4 datos sólo dos (los dos últimos) son clasificados correctamente."
      ],
      "metadata": {
        "id": "TXde_L7P-KDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. *Pipelines* (tuberías????)\n",
        "\n",
        "Es posible combinar transformadores y estimadores en un sólo objeto: una *pipeline*.\n",
        "\n",
        "Una *pipeline* nos permite hacer lo mismo que con los bloques separados, pero tiene ciertas ventajas:\n",
        "\n",
        "1. El código es más compacto\n",
        "2. Evita lo que se conoce como la fuga de datos (*data leakage*): que los datos de validación sean \"vistos\" por el modelo cuando hacemos el entrenamiento\n",
        "\n",
        "Para hacer un comparativo veamos primero cómo sería el flujo completo de trabajo sin *pipelines*:"
      ],
      "metadata": {
        "id": "Zy6KK9A7jtdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flujo de trabajo sin \"pipelines\"\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Leer datos\n",
        "X = np.load('/content/particiones-datos-balanceados.npz')['X']\n",
        "Y = np.load('/content/particiones-datos-balanceados.npz')['Y']\n",
        "\n",
        "# Partición en entrenamiento, validación y prueba\n",
        "x_train, x_resto, y_train, y_resto = train_test_split(\n",
        "    X, Y, test_size=0.4, random_state=123\n",
        ")\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_resto, y_resto, test_size=0.5, random_state=321\n",
        ")\n",
        "\n",
        "# Escalamiento\n",
        "scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "x_train_s = scaler.fit_transform(x_train)\n",
        "x_val_s = scaler.transform(x_val)\n",
        "x_test_s = scaler.transform(x_test)\n",
        "\n",
        "# Creación, entrenamiento y validación del modelo\n",
        "bosque = RandomForestClassifier()\n",
        "bosque.fit(x_train, y_train)\n",
        "print(bosque.score(x_test,y_test))\n",
        "\n",
        "# Generación de predicciones\n",
        "print(bosque.predict(x_test))"
      ],
      "metadata": {
        "id": "5Mf8IgeIYfAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39081930-570f-4c98-b003-136b7ee3de15"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n",
            "[0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Con pipelines\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Leer datos\n",
        "X = np.load('/content/particiones-datos-balanceados.npz')['X']\n",
        "Y = np.load('/content/particiones-datos-balanceados.npz')['Y']\n",
        "\n",
        "# Partición en entrenamiento, validación y prueba\n",
        "x_train, x_resto, y_train, y_resto = train_test_split(\n",
        "    X, Y, test_size=0.4, random_state=123\n",
        ")\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_resto, y_resto, test_size=0.5, random_state=321\n",
        ")\n",
        "\n",
        "#------- PIPELINE: SE INTERCONECTAN PREPROCESAMIENTO Y MODELO -------\n",
        "\n",
        "# Instanciar la pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler(feature_range=(-1,1))),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# Entrenar la pipeline\n",
        "pipeline.fit(x_train, y_train)\n",
        "\n",
        "# Evaluar la pipeline\n",
        "print(pipeline.score(x_test, y_test))\n",
        "\n",
        "# Y generar predicciones\n",
        "print(pipeline.predict(x_test))"
      ],
      "metadata": {
        "id": "H8jIUSzGYhGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0149877b-a6b6-45e2-8ed5-dfeb7f6b74dc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n",
            "[0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3arcgVDUsq1c"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}